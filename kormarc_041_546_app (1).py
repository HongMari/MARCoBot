import re
import os
import streamlit as st
import requests
import xml.etree.ElementTree as ET
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
load_dotenv()
ALADIN_KEY = os.getenv("ALADIN_TTB_KEY", "ttbdawn63091003001")

# ISDS ì–¸ì–´ì½”ë“œ ë§¤í•‘
ISDS_LANGUAGE_CODES = {
    'kor': 'í•œêµ­ì–´', 'eng': 'ì˜ì–´', 'jpn': 'ì¼ë³¸ì–´', 'chi': 'ì¤‘êµ­ì–´',
    'rus': 'ëŸ¬ì‹œì•„ì–´', 'ara': 'ì•„ëì–´', 'fre': 'í”„ë‘ìŠ¤ì–´', 'ger': 'ë…ì¼ì–´',
    'ita': 'ì´íƒˆë¦¬ì•„ì–´', 'spa': 'ìŠ¤í˜ì¸ì–´', 'por': 'í¬ë¥´íˆ¬ê°ˆì–´', 'tur': 'í„°í‚¤ì–´',
    'und': 'ì•Œ ìˆ˜ ì—†ìŒ'
}

# ìœ ë‹ˆì½”ë“œ ë²”ìœ„ ê¸°ë°˜ ì–¸ì–´ ê°ì§€
def detect_language_by_unicode(text):
    text = re.sub(r'[\s\W_]+', '', text)
    if not text:
        return 'und'
    first_char = text[0]
    if '\uac00' <= first_char <= '\ud7a3':
        return 'kor'
    elif '\u3040' <= first_char <= '\u30ff':
        return 'jpn'
    elif '\u4e00' <= first_char <= '\u9fff':
        return 'chi'
    elif '\u0600' <= first_char <= '\u06FF':
        return 'ara'
    elif '\u0e00' <= first_char <= '\u0e7f':
        return 'tha'
    elif 'a' <= first_char.lower() <= 'z':
        return 'eng'
    return 'und'

# ì–¸ì–´ í‚¤ì›Œë“œ ë° íŠ¹ìˆ˜ë¬¸ì ê¸°ë°˜ ì˜¤ë²„ë¼ì´ë“œ
def override_language_by_keywords(text, initial_lang):
    text = text.lower()

    if initial_lang == 'chi' and re.search(r'[\u3040-\u30ff]', text):
        return 'jpn'

    if initial_lang == 'eng':
        if "spanish" in text or "espaÃ±ol" in text:
            return "spa"
        if "italian" in text or "italiano" in text:
            return "ita"
        if "french" in text or "franÃ§ais" in text:
            return "fre"
        if "portuguese" in text or "portuguÃªs" in text:
            return "por"
        if "german" in text or "deutsch" in text:
            return "ger"
        if any(ch in text for ch in ['Ã©', 'Ã¨', 'Ãª', 'Ã ', 'Ã§', 'Ã¹', 'Ã´', 'Ã¢', 'Ã®', 'Ã»']):
            return "fre"
        if any(ch in text for ch in ['Ã±', 'Ã¡', 'Ã­', 'Ã³', 'Ãº']):
            return "spa"
        if any(ch in text for ch in ['Ã£', 'Ãµ']):
            return "por"

    return initial_lang

# ì¢…í•© ì–¸ì–´ ê°ì§€
def detect_language(text):
    lang = detect_language_by_unicode(text)
    return override_language_by_keywords(text, lang)

# ì¹´í…Œê³ ë¦¬ì—ì„œ ì–¸ì–´ ì¶”ì •
def detect_language_from_category(text):
    words = re.split(r'[>/>\s]+', text)
    for word in words:
        if "ì¼ë³¸" in word:
            return "jpn"
        elif "ì¤‘êµ­" in word:
            return "chi"
        elif "ì˜ë¯¸" in word or "ì˜ì–´" in word or "ì•„ì¼ëœë“œ" in word:
            return "eng"
        elif "í”„ë‘ìŠ¤" in word:
            return "fre"
        elif "ë…ì¼" in word or "ì˜¤ìŠ¤íŠ¸ë¦¬ì•„" in word:
            return "ger"
        elif "ëŸ¬ì‹œì•„" in word:
            return "rus"
        elif "ì´íƒˆë¦¬ì•„" in word:
            return "ita"
        elif "ìŠ¤í˜ì¸" in word:
            return "spa"
        elif "í¬ë¥´íˆ¬ê°ˆ" in word:
            return "por"
        elif "íŠ€ë¥´í‚¤ì˜ˆ" in word or "í„°í‚¤" in word:
            return "tur"
    return None

# 546 íƒœê·¸ ìƒì„±
def generate_546_from_041_kormarc(marc_041: str) -> str:
    a_codes, h_code = [], None
    for part in marc_041.split():
        if part.startswith("$a"):
            a_codes.append(part[2:])
        elif part.startswith("$h"):
            h_code = part[2:]
    if len(a_codes) == 1:
        a_lang = ISDS_LANGUAGE_CODES.get(a_codes[0], "ì•Œ ìˆ˜ ì—†ìŒ")
        if h_code:
            h_lang = ISDS_LANGUAGE_CODES.get(h_code, "ì•Œ ìˆ˜ ì—†ìŒ")
            return f"{a_lang}ë¡œ ì”€, ì›ì €ëŠ” {h_lang}ì„"
        else:
            return f"{a_lang}ë¡œ ì”€"
    elif len(a_codes) > 1:
        langs = [ISDS_LANGUAGE_CODES.get(code, "ì•Œ ìˆ˜ ì—†ìŒ") for code in a_codes]
        return f"{'ã€'.join(langs)} ë³‘ê¸°"
    return "ì–¸ì–´ ì •ë³´ ì—†ìŒ"

# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì œê±°
def strip_ns(tag):
    return tag.split('}')[-1] if '}' in tag else tag

# ì•Œë¼ë”˜ ì›¹í˜ì´ì§€ í¬ë¡¤ë§
def crawl_aladin_fallback(isbn13):
    url = f"https://www.aladin.co.kr/shop/wproduct.aspx?ISBN={isbn13}"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, "html.parser")
        original = soup.select_one("div.info_original")
        lang_info = soup.select_one("div.conts_info_list1")

        category_text = ""
        categories = soup.select("div.conts_info_list2 li")
        for cat in categories:
            category_text += cat.get_text(separator=" ", strip=True) + " "

        st.write("ğŸ“˜ [DEBUG] category_text =", category_text)
        category_lang = detect_language_from_category(category_text)
        st.write("ğŸ“˜ [DEBUG] category_lang =", category_lang)

        detected_lang = ""
        if lang_info and "ì–¸ì–´" in lang_info.text:
            if "Japanese" in lang_info.text:
                detected_lang = "jpn"
            elif "Chinese" in lang_info.text:
                detected_lang = "chi"
            elif "English" in lang_info.text:
                detected_lang = "eng"

        return {
            "original_title": original.text.strip() if original else "",
            "subject_lang": category_lang or detected_lang
        }
    except Exception as e:
        st.error(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {}

# KORMARC íƒœê·¸ ìƒì„±
def get_kormarc_tags(isbn):
    isbn = isbn.strip().replace("-", "")
    url = "http://www.aladin.co.kr/ttb/api/ItemLookUp.aspx"
    params = {
        "ttbkey": ALADIN_KEY,
        "itemIdType": "ISBN13",
        "ItemId": isbn,
        "output": "xml",
        "Version": "20131101"
    }

    try:
        response = requests.get(url, params=params)
        if response.status_code != 200:
            raise ValueError("API í˜¸ì¶œ ì‹¤íŒ¨")

        root = ET.fromstring(response.content)
        for elem in root.iter():
            elem.tag = strip_ns(elem.tag)

        item = root.find("item")
        if item is None:
            raise ValueError("<item> íƒœê·¸ ì—†ìŒ")

        title = item.findtext("title", default="")
        subinfo = item.find("subInfo")
        original_title = subinfo.findtext("originalTitle") if subinfo is not None else ""

        crawl = crawl_aladin_fallback(isbn)
        if not original_title:
            original_title = crawl.get("original_title", "")
        subject_lang = crawl.get("subject_lang")

        lang_a = detect_language(title)
        lang_h = subject_lang or detect_language(original_title)

        tag_041 = f"041 $a{lang_a}" + (
            f" $h{lang_h}" if lang_h and lang_h != lang_a and lang_h != "und" else ""
        )
        tag_546 = generate_546_from_041_kormarc(tag_041)

        return tag_041, tag_546, original_title

    except Exception as e:
        return f"ğŸ“• ì˜ˆì™¸ ë°œìƒ: {e}", "", ""

# âœ… Streamlit UI ì‹œì‘
st.title("ğŸ“˜ KORMARC 041/546 íƒœê·¸ ìƒì„±ê¸° (ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ì–¸ì–´ ê°ì§€ í¬í•¨)")

isbn_input = st.text_input("ISBNì„ ì…ë ¥í•˜ì„¸ìš” (13ìë¦¬):")
if st.button("íƒœê·¸ ìƒì„±"):
    if isbn_input:
        try:
            tag_041, tag_546, original = get_kormarc_tags(isbn_input)
            st.text(f"ğŸ“„ 041 íƒœê·¸: {tag_041}")
            if tag_546:
                st.text(f"ğŸ“„ 546 íƒœê·¸: {tag_546}")
            if original:
                st.text(f"ğŸ“• ì›ì œ: {original}")
        except Exception as e:
            st.error(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
    else:
        st.warning("ISBNì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
