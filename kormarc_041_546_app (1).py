import re
import os
import streamlit as st
import requests
import xml.etree.ElementTree as ET
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from openai import OpenAI

# ===== í™˜ê²½ë³€ìˆ˜ ë¡œë“œ =====
load_dotenv()
ALADIN_KEY = os.getenv("ALADIN_TTB_KEY")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_KEY)

# ===== ISDS ì–¸ì–´ì½”ë“œ ë§¤í•‘ =====
ISDS_LANGUAGE_CODES = {
    'kor': 'í•œêµ­ì–´', 'eng': 'ì˜ì–´', 'jpn': 'ì¼ë³¸ì–´', 'chi': 'ì¤‘êµ­ì–´',
    'rus': 'ëŸ¬ì‹œì•„ì–´', 'ara': 'ì•„ëì–´', 'fre': 'í”„ë‘ìŠ¤ì–´', 'ger': 'ë…ì¼ì–´',
    'ita': 'ì´íƒˆë¦¬ì•„ì–´', 'spa': 'ìŠ¤í˜ì¸ì–´', 'por': 'í¬ë¥´íˆ¬ê°ˆì–´', 'tur': 'í„°í‚¤ì–´',
    'und': 'ì•Œ ìˆ˜ ì—†ìŒ'
}

# ===== GPT íŒë‹¨ í•¨ìˆ˜ =====
def gpt_guess_original_lang(title, category, publisher, author="", original_title=""):
    prompt = f"""
    ë‹¤ìŒ ë„ì„œì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì›ì„œì˜ ì–¸ì–´(041 $h)ë¥¼ ISDS ì½”ë“œ(kor, eng, jpn, chi, rus, fre, ger, ita, spa, por, tur) ì¤‘ í•˜ë‚˜ë¡œ ê²°ì •í•´ì¤˜.
    - ì œëª©: {title}
    - ì›ì œ: {original_title}
    - ë¶„ë¥˜(ì¹´í…Œê³ ë¦¬ ê²½ë¡œ/í…ìŠ¤íŠ¸): {category}
    - ì¶œíŒì‚¬: {publisher}
    - ì €ì: {author}

    ì¹´í…Œê³ ë¦¬ì— êµ­ê°€/ì§€ì—­ ë‹¨ì„œê°€ ìˆëŠ” ê²½ìš° ê·¸ ì–¸ì–´ë¥¼ ìš°ì„  ê³ ë ¤í•˜ê³ , ì›ì œ ë¬¸ìì—´ì´ í•´ë‹¹ ì–¸ì–´ ë¬¸ìì¸ì§€ ê°„ë‹¨íˆ êµì°¨ í™•ì¸í•œ ë‹¤ìŒ ê²°ì •í•´.
    ì‘ë‹µì€ ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ:
    $h=[ISDS ì½”ë“œ]
    """
    try:
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë„ì„œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì›ì„œ ì–¸ì–´ë¥¼ íŒë‹¨í•˜ëŠ” ì‚¬ì„œ AIì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0
        )
        content = resp.choices[0].message.content.strip()
        return content.replace("$h=", "").strip() if content.startswith("$h=") else "und"
    except Exception as e:
        st.error(f"GPT ì˜¤ë¥˜: {e}")
        return "und"

def gpt_guess_main_lang(title, category, publisher, author=""):
    prompt = f"""
    ë‹¤ìŒ ë„ì„œì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³¸ë¬¸ ì–¸ì–´(041 $a)ë¥¼ ISDS ì½”ë“œ(kor, eng, jpn, chi, rus, fre, ger, ita, spa, por, tur) ì¤‘ í•˜ë‚˜ë¡œ ê²°ì •í•´ì¤˜.
    - ì œëª©: {title}
    - ë¶„ë¥˜(ì¹´í…Œê³ ë¦¬ ê²½ë¡œ/í…ìŠ¤íŠ¸): {category}
    - ì¶œíŒì‚¬: {publisher}
    - ì €ì: {author}
    ì‘ë‹µì€ ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ:
    $a=[ISDS ì½”ë“œ]
    """
    try:
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë„ì„œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³¸ë¬¸ ì–¸ì–´ë¥¼ íŒë‹¨í•˜ëŠ” ì‚¬ì„œ AIì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0
        )
        content = resp.choices[0].message.content.strip()
        return content.replace("$a=", "").strip() if content.startswith("$a=") else "und"
    except Exception as e:
        st.error(f"GPT ì˜¤ë¥˜: {e}")
        return "und"

# ===== ìœ ë‹ˆì½”ë“œ/í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì§€ =====
def detect_language_by_unicode(text):
    text = re.sub(r'[\s\W_]+', '', text)
    if not text:
        return 'und'
    first_char = text[0]
    if '\uac00' <= first_char <= '\ud7a3': return 'kor'
    elif '\u3040' <= first_char <= '\u30ff': return 'jpn'
    elif '\u4e00' <= first_char <= '\u9fff': return 'chi'
    elif '\u0600' <= first_char <= '\u06FF': return 'ara'
    elif '\u0e00' <= first_char <= '\u0e7f': return 'tha'
    return 'und'

def override_language_by_keywords(text, initial_lang):
    text = text.lower()
    if initial_lang == 'chi' and re.search(r'[\u3040-\u30ff]', text): return 'jpn'
    if initial_lang in ['und', 'eng']:
        if "spanish" in text or "espaÃ±ol" in text: return "spa"
        if "italian" in text or "italiano" in text: return "ita"
        if "french" in text or "franÃ§ais" in text: return "fre"
        if "portuguese" in text or "portuguÃªs" in text: return "por"
        if "german" in text or "deutsch" in text: return "ger"
        if any(ch in text for ch in ['Ã©','Ã¨','Ãª','Ã ','Ã§','Ã¹','Ã´','Ã¢','Ã®','Ã»']): return "fre"
        if any(ch in text for ch in ['Ã±','Ã¡','Ã­','Ã³','Ãº']): return "spa"
        if any(ch in text for ch in ['Ã£','Ãµ']): return "por"
    return initial_lang

def detect_language(text):
    lang = detect_language_by_unicode(text)
    return override_language_by_keywords(text, lang)

# ===== ì¹´í…Œê³ ë¦¬(êµ­ê°€/ì§€ì—­) ê¸°ë°˜ ì–¸ì–´ ë§¤í•‘ =====
def detect_language_from_category(cat_text):
    # ìì£¼ ë³´ì´ëŠ” êµ­ê°€/ì§€ì—­ í‚¤ì›Œë“œ í™•ì¥
    mapping = [
        ("ì¼ë³¸", "jpn"),
        ("ì¤‘êµ­", "chi"), ("ëŒ€ë§Œ", "chi"), ("í™ì½©", "chi"),
        ("ì˜ë¯¸", "eng"), ("ì˜ì–´", "eng"), ("ì˜êµ­", "eng"), ("ë¯¸êµ­", "eng"),
        ("ìºë‚˜ë‹¤", "eng"), ("í˜¸ì£¼", "eng"), ("ì•„ì¼ëœë“œ", "eng"), ("ë‰´ì§ˆëœë“œ", "eng"),
        ("í”„ë‘ìŠ¤", "fre"),
        ("ë…ì¼", "ger"), ("ì˜¤ìŠ¤íŠ¸ë¦¬ì•„", "ger"),
        ("ëŸ¬ì‹œì•„", "rus"),
        ("ì´íƒˆë¦¬ì•„", "ita"),
        ("ìŠ¤í˜ì¸", "spa"),
        ("í¬ë¥´íˆ¬ê°ˆ", "por"), ("ë¸Œë¼ì§ˆ", "por"),
        ("íŠ€ë¥´í‚¤ì˜ˆ", "tur"), ("í„°í‚¤", "tur"),
        ("ì•„ë", "ara"), ("ì¤‘ë™", "ara")  # í•„ìš”ì‹œ í™•ì¥
    ]
    if not cat_text:
        return None
    for key, code in mapping:
        if key in cat_text:
            return code
    return None

# ===== 546 ìƒì„± =====
def generate_546_from_041_kormarc(marc_041):
    a_codes, h_code = [], None
    for part in marc_041.split():
        if part.startswith("$a"): a_codes.append(part[2:])
        elif part.startswith("$h"): h_code = part[2:]
    if len(a_codes) == 1:
        a_lang = ISDS_LANGUAGE_CODES.get(a_codes[0], "ì•Œ ìˆ˜ ì—†ìŒ")
        if h_code:
            h_lang = ISDS_LANGUAGE_CODES.get(h_code, "ì•Œ ìˆ˜ ì—†ìŒ")
            return f"{a_lang}ë¡œ ì”€, ì›ì €ëŠ” {h_lang}ì„"
        else:
            return f"{a_lang}ë¡œ ì”€"
    elif len(a_codes) > 1:
        langs = [ISDS_LANGUAGE_CODES.get(code, "ì•Œ ìˆ˜ ì—†ìŒ") for code in a_codes]
        return f"{'ã€'.join(langs)} ë³‘ê¸°"
    return "ì–¸ì–´ ì •ë³´ ì—†ìŒ"

# ===== ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì œê±° =====
def strip_ns(tag): return tag.split('}')[-1] if '}' in tag else tag

# ===== ì•Œë¼ë”˜ ìƒì„¸ í˜ì´ì§€ì—ì„œ ë³´ì¡° ì •ë³´ í¬ë¡¤ë§ =====
def crawl_aladin_fallback(isbn13):
    url = f"https://www.aladin.co.kr/shop/wproduct.aspx?ISBN={isbn13}"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, "html.parser")
        original = soup.select_one("div.info_original")
        lang_info = soup.select_one("div.conts_info_list1")
        category_text = ""
        categories = soup.select("div.conts_info_list2 li")
        for cat in categories:
            category_text += cat.get_text(separator=" ", strip=True) + " "
        detected_lang = ""
        if lang_info and "ì–¸ì–´" in lang_info.text:
            if "Japanese" in lang_info.text: detected_lang = "jpn"
            elif "Chinese" in lang_info.text: detected_lang = "chi"
            elif "English" in lang_info.text: detected_lang = "eng"
        return {
            "original_title": original.text.strip() if original else "",
            "subject_lang": detect_language_from_category(category_text) or detected_lang,
            "category_text": category_text
        }
    except Exception as e:
        st.error(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {}

# ===== KORMARC íƒœê·¸ ìƒì„± =====
def get_kormarc_tags(isbn):
    isbn = isbn.strip().replace("-", "")
    url = "http://www.aladin.co.kr/ttb/api/ItemLookUp.aspx"
    params = {
        "ttbkey": ALADIN_KEY,
        "itemIdType": "ISBN13",
        "ItemId": isbn,
        "output": "xml",
        "Version": "20131101"
    }
    try:
        response = requests.get(url, params=params, timeout=15)
        if response.status_code != 200:
            raise ValueError("API í˜¸ì¶œ ì‹¤íŒ¨")
        root = ET.fromstring(response.content)
        for elem in root.iter():
            elem.tag = strip_ns(elem.tag)
        item = root.find("item")
        if item is None:
            raise ValueError("<item> íƒœê·¸ ì—†ìŒ")

        title = item.findtext("title", default="")
        publisher = item.findtext("publisher", default="")
        author = item.findtext("author", default="")
        subinfo = item.find("subInfo")
        original_title = subinfo.findtext("originalTitle") if subinfo is not None else ""

        crawl = crawl_aladin_fallback(isbn)
        if not original_title:
            original_title = crawl.get("original_title", "")
        subject_lang_from_cat = crawl.get("subject_lang")  # ì´ë¯¸ detect_language_from_category ì ìš©ë¨
        category_text = crawl.get("category_text", "")

        # ===== $a íŒë‹¨ (ë³¸ë¬¸ ì–¸ì–´) =====
        lang_a = detect_language(title)
        st.write("ğŸ“˜ [DEBUG][$a] ì œëª© ê¸°ë°˜ ì´ˆê¹ƒê°’ =", lang_a)
        if lang_a in ['und', 'eng']:  # ì˜ë¬¸ ì œëª©ì¸ë° ì‹¤ì œ ë³¸ë¬¸ì´ í•œêµ­ì–´ì¼ ìˆ˜ ìˆì–´ GPT ë³´ì™„
            st.write("ğŸ“˜ [DEBUG][$a] GPT ìš”ì²­ (title/category/publisher/author) â†’", title, category_text, publisher, author)
            gpt_a = gpt_guess_main_lang(title, category_text, publisher, author)
            st.write("ğŸ“˜ [DEBUG][$a] GPT íŒë‹¨ =", gpt_a)
            if gpt_a != 'und':
                lang_a = gpt_a

        # ===== $h íŒë‹¨ (ì›ì„œ ì–¸ì–´) =====
        # 1) ì›ì œ ë¬¸ìì—´ ê¸°ë°˜
        lang_h_first = detect_language(original_title) if original_title else "und"
        if original_title:
            st.write("ğŸ“˜ [DEBUG][$h] ì›ì œ ê°ì§€ë¨:", original_title)
            st.write("ğŸ“˜ [DEBUG][$h] ì›ì œ ê¸°ë°˜ 1ì°¨ =", lang_h_first)
        else:
            st.write("ğŸ“˜ [DEBUG][$h] ì›ì œ ì—†ìŒ")

        # 2) ì¹´í…Œê³ ë¦¬(êµ­ê°€/ì§€ì—­) ê¸°ë°˜ â†’ GPTë³´ë‹¤ ìš°ì„ 
        lang_h_cat = subject_lang_from_cat or detect_language_from_category(category_text)
        st.write("ğŸ“˜ [DEBUG][$h] ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í›„ë³´ =", lang_h_cat)

        # ê²°ì • ë¡œì§: ì›ì œ ì–¸ì–´ or ì¹´í…Œê³ ë¦¬ ì–¸ì–´ ì¤‘ ì‹ ë¢°ë˜ëŠ” ê²ƒì„ ë¨¼ì € ì‚¬ìš©
        lang_h = "und"
        decision = ""

        if lang_h_first != "und":
            lang_h = lang_h_first
            decision = "ì›ì œ(ë¬¸ìêµ°)ë¡œ í™•ì •"
        elif lang_h_cat:
            lang_h = lang_h_cat
            decision = "ì¹´í…Œê³ ë¦¬(êµ­ê°€/ì§€ì—­)ë¡œ í™•ì •"
        else:
            decision = "ë³´ì™„ í•„ìš” â†’ GPTë¡œ íŒë‹¨"

        # 3) ì—¬ì „íˆ undë©´ GPT ë³´ì™„
        if lang_h == "und":
            st.write("ğŸ“˜ [DEBUG][$h] GPT ë³´ì™„ ìš”ì²­ (title/category/publisher/author/original) â†’",
                     title, category_text, publisher, author, original_title)
            lang_h = gpt_guess_original_lang(title, category_text, publisher, author, original_title)
            st.write("ğŸ“˜ [DEBUG][$h] GPT íŒë‹¨ =", lang_h)
            if lang_h != "und":
                decision = "GPTë¡œ í™•ì •"

        st.write(f"ğŸ“˜ [DEBUG][$h] ìµœì¢… = {lang_h}  (ê²°ì • ê·¼ê±°: {decision})")

        # ===== íƒœê·¸ ìƒì„± =====
        if lang_h and lang_h != lang_a and lang_h != "und":
            tag_041 = f"041 $a{lang_a} $h{lang_h}"
        else:
            tag_041 = f"041 $a{lang_a}"
        tag_546 = generate_546_from_041_kormarc(tag_041)

        return tag_041, tag_546, original_title
    except Exception as e:
        return f"ğŸ“• ì˜ˆì™¸ ë°œìƒ: {e}", "", ""

# ===== Streamlit UI =====
st.title("ğŸ“˜ KORMARC 041/546 íƒœê·¸ ìƒì„±ê¸° (ì¹´í…Œê³ ë¦¬ ìš°ì„  â†’ GPT ë³´ì™„)")

isbn_input = st.text_input("ISBNì„ ì…ë ¥í•˜ì„¸ìš” (13ìë¦¬):")
if st.button("íƒœê·¸ ìƒì„±"):
    if isbn_input:
        try:
            tag_041, tag_546, original = get_kormarc_tags(isbn_input)
            st.text(f"ğŸ“„ 041 íƒœê·¸: {tag_041}")
            if tag_546:
                st.text(f"ğŸ“„ 546 íƒœê·¸: {tag_546}")
            if original:
                st.text(f"ğŸ“• ì›ì œ: {original}")
        except Exception as e:
            st.error(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
    else:
        st.warning("ISBNì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
