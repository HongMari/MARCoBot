
import re
import os
import openai
import streamlit as st
import requests
import xml.etree.ElementTree as ET
from bs4 import BeautifulSoup
from dotenv import load_dotenv

load_dotenv()
ALADIN_KEY = os.getenv("ALADIN_TTB_KEY")
openai.api_key = os.getenv("OPENAI_API_KEY")

ISDS_LANGUAGE_CODES = {
    'kor': 'í•œêµ­ì–´', 'eng': 'ì˜ì–´', 'jpn': 'ì¼ë³¸ì–´', 'chi': 'ì¤‘êµ­ì–´',
    'rus': 'ëŸ¬ì‹œì•„ì–´', 'ara': 'ì•„ëì–´', 'fre': 'í”„ë‘ìŠ¤ì–´', 'ger': 'ë…ì¼ì–´',
    'ita': 'ì´íƒˆë¦¬ì•„ì–´', 'spa': 'ìŠ¤í˜ì¸ì–´', 'por': 'í¬ë¥´íˆ¬ê°ˆì–´', 'tur': 'í„°í‚¤ì–´',
    'und': 'ì•Œ ìˆ˜ ì—†ìŒ'
}

def gpt_guess_lang(title, category, publisher, author=""):
    roman_hint = "ì´ ë„ì„œì˜ ì œëª©ì€ ë¡œë§ˆì í‘œê¸°ë¡œ ë˜ì–´ ìˆì§€ë§Œ ë°˜ë“œì‹œ ì˜ì–´(eng)ë¼ëŠ” ë³´ì¥ì€ ì—†ìŠµë‹ˆë‹¤.\n" if re.match(r'^[A-Za-z0-9\s\W]+$', title) else ""
    prompt = f"""
    {roman_hint}
    ë‹¤ìŒ ë„ì„œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì›ì„œì˜ ì–¸ì–´(041 $h)ë¥¼ ISDS ì½”ë“œë¡œ ì •í™•íˆ ì¶”ì •í•´ì¤˜.
    - ì œëª©: {title}
    - ë¶„ë¥˜: {category}
    - ì¶œíŒì‚¬: {publisher}
    - ì €ì: {author}

    ê°€ëŠ¥í•œ ISDS ì–¸ì–´ì½”ë“œ: kor, eng, jpn, chi, rus, fre, ger, ita, spa, por, tur
    ì‘ë‹µ í˜•ì‹: $h=[ISDS ì½”ë“œ]
    """
    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë„ì„œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì–¸ì–´ë¥¼ ê°ë³„í•˜ëŠ” ì‚¬ì„œ AIì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0
        )
        result = response.choices[0].message.content.strip()
        if result.startswith("$h="):
            return result[3:].strip()
    except Exception as e:
        st.error(f"GPT ì˜¤ë¥˜: {e}")
    return "und"

def detect_language_by_unicode(text):
    text = re.sub(r'[\s\W_]+', '', text)
    if not text: return 'und'
    ch = text[0]
    if '\uac00' <= ch <= '\ud7a3': return 'kor'
    elif '\u3040' <= ch <= '\u30ff': return 'jpn'
    elif '\u4e00' <= ch <= '\u9fff': return 'chi'
    elif '\u0600' <= ch <= '\u06FF': return 'ara'
    elif '\u0e00' <= ch <= '\u0e7f': return 'tha'
    return 'und'

def override_by_keywords(text, lang):
    text = text.lower()
    if lang == 'chi' and re.search(r'[\u3040-\u30ff]', text): return 'jpn'
    if lang in ['und', 'eng']:
        if "french" in text or "franÃ§ais" in text or any(ch in text for ch in ['Ã©', 'Ã¨']): return "fre"
        if "spanish" in text or "espaÃ±ol" in text or 'Ã±' in text: return "spa"
        if "german" in text or "deutsch" in text: return "ger"
        if "italian" in text or "italiano" in text: return "ita"
        if "portuguese" in text or "portuguÃªs" in text: return "por"
    return lang

def detect_language(text):
    return override_by_keywords(text, detect_language_by_unicode(text))

def detect_from_category(text):
    if any(w in text for w in ["ì¼ë³¸"]): return "jpn"
    if any(w in text for w in ["ì¤‘êµ­"]): return "chi"
    if any(w in text for w in ["ì˜ë¯¸", "ì˜ì–´", "ì•„ì¼ëœë“œ"]): return "eng"
    if "í”„ë‘ìŠ¤" in text: return "fre"
    if any(w in text for w in ["ë…ì¼", "ì˜¤ìŠ¤íŠ¸ë¦¬ì•„"]): return "ger"
    if "ëŸ¬ì‹œì•„" in text: return "rus"
    if "ì´íƒˆë¦¬ì•„" in text: return "ita"
    if "ìŠ¤í˜ì¸" in text: return "spa"
    if "í¬ë¥´íˆ¬ê°ˆ" in text: return "por"
    if any(w in text for w in ["íŠ€ë¥´í‚¤ì˜ˆ", "í„°í‚¤"]): return "tur"
    return None

def generate_546(marc_041):
    a_codes, h_code = [], None
    for part in marc_041.split():
        if part.startswith("$a"): a_codes.append(part[2:])
        elif part.startswith("$h"): h_code = part[2:]
    if len(a_codes) == 1:
        a = ISDS_LANGUAGE_CODES.get(a_codes[0], "ì•Œ ìˆ˜ ì—†ìŒ")
        h = ISDS_LANGUAGE_CODES.get(h_code, "ì•Œ ìˆ˜ ì—†ìŒ") if h_code else None
        return f"{a}ë¡œ ì”€, ì›ì €ëŠ” {h}ì„" if h else f"{a}ë¡œ ì”€"
    elif len(a_codes) > 1:
        langs = [ISDS_LANGUAGE_CODES.get(code, "ì•Œ ìˆ˜ ì—†ìŒ") for code in a_codes]
        return f"{'ã€'.join(langs)} ë³‘ê¸°"
    return "ì–¸ì–´ ì •ë³´ ì—†ìŒ"

def strip_ns(tag): return tag.split('}')[-1] if '}' in tag else tag

def crawl_aladin(isbn):
    url = f"https://www.aladin.co.kr/shop/wproduct.aspx?ISBN={isbn}"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, "html.parser")
        original = soup.select_one("div.info_original")
        categories = soup.select("div.conts_info_list2 li")
        category_text = " ".join([c.get_text(" ", strip=True) for c in categories])
        return {
            "original_title": original.text.strip() if original else "",
            "category_text": category_text
        }
    except Exception as e:
        st.error(f"í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        return {"original_title": "", "category_text": ""}

# $h ì›ì„œ ì–¸ì–´ íŒë‹¨
def guess_lang_h(original_title, category, publisher, author):
    if original_title:
        return detect_language(original_title)
    if re.search(r'[ê°€-í£]', author):
        st.write("ğŸ“˜ [DEBUG][$h] ì €ìëª… í•œê¸€ â†’ í•œêµ­ì–´")
        return "kor"
    if re.search(r'[ä¸€-é¾¥]', author): return "chi"
    if re.search(r'[ã-ã‚“ã‚¡-ãƒ³]', author): return "jpn"
    cat_lang = detect_from_category(category)
    if cat_lang:
        st.write("ğŸ“˜ [DEBUG][$h] ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ íŒë‹¨ =", cat_lang)
        return cat_lang
    st.write("ğŸ“˜ [DEBUG][$h] GPT ìš”ì²­ â†’", original_title, category, publisher, author)
    return gpt_guess_lang(original_title or "ì—†ìŒ", category, publisher, author)

def get_kormarc_tags(isbn):
    isbn = isbn.strip().replace("-", "")
    url = "http://www.aladin.co.kr/ttb/api/ItemLookUp.aspx"
    params = {
        "ttbkey": ALADIN_KEY,
        "itemIdType": "ISBN13",
        "ItemId": isbn,
        "output": "xml",
        "Version": "20131101"
    }
    try:
        r = requests.get(url, params=params)
        if r.status_code != 200: raise Exception("API ì˜¤ë¥˜")
        root = ET.fromstring(r.content)
        for e in root.iter(): e.tag = strip_ns(e.tag)

        item = root.find("item")
        if item is None: raise Exception("item íƒœê·¸ ì—†ìŒ")

        title = item.findtext("title", default="")
        publisher = item.findtext("publisher", default="")
        author = item.findtext("author", default="")
        subinfo = item.find("subInfo")
        original_title = subinfo.findtext("originalTitle") if subinfo is not None else ""

        crawl = crawl_aladin(isbn)
        if not original_title:
            original_title = crawl["original_title"]
        category_text = crawl["category_text"]

        lang_a = detect_language(title)
        if lang_a == "und":
            lang_a = detect_from_category(category_text) or gpt_guess_lang(title, category_text, publisher, author)
        st.write("ğŸ“˜ [DEBUG][$a] ìµœì¢… íŒë‹¨ =", lang_a)

        lang_h = guess_lang_h(original_title, category_text, publisher, author)
        st.write("ğŸ“˜ [DEBUG][$h] ìµœì¢… íŒë‹¨ =", lang_h)

        if lang_h and lang_h != lang_a and lang_h != "und":
            tag_041 = f"041 $a{lang_a} $h{lang_h}"
        else:
            tag_041 = f"041 $a{lang_a}"
        tag_546 = generate_546(tag_041)
        return tag_041, tag_546, original_title

    except Exception as e:
        return f"ğŸ“• ì˜¤ë¥˜: {e}", "", ""

# UI
st.title("ğŸ“˜ KORMARC 041/546 íƒœê·¸ ìƒì„±ê¸°")

isbn_input = st.text_input("ISBNì„ ì…ë ¥í•˜ì„¸ìš” (13ìë¦¬):")
if st.button("íƒœê·¸ ìƒì„±"):
    if isbn_input:
        tag_041, tag_546, original = get_kormarc_tags(isbn_input)
        st.text(f"ğŸ“„ 041 íƒœê·¸: {tag_041}")
        if tag_546: st.text(f"ğŸ“„ 546 íƒœê·¸: {tag_546}")
        if original: st.text(f"ğŸ“• ì›ì œ: {original}")
    else:
        st.warning("ISBNì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
